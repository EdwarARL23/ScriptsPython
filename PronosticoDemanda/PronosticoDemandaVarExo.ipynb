{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acb405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "DEMANDA ELÉCTRICA HORARIA – MODELO HÍBRIDO (Ridge + Boosting) CON DATOS SIMULADOS\n",
    "=================================================================================\n",
    "\n",
    "OBJETIVO\n",
    "--------\n",
    "Pronosticar demanda eléctrica **horaria** por **subárea** para los próximos **90 días (~3 meses)**,\n",
    "usando 5 años de historia simulada. Se implementa un **modelo híbrido**:\n",
    "\n",
    "(A) **Regresión Ridge con Fourier + ARX (Dynamic Harmonic Regression)**\n",
    "    - Captura estacionalidades **diaria** (24 h) y **semanal** (168 h) mediante términos de\n",
    "      **Fourier**: senos/cosenos con distintos armónicos. Esto aproxima ciclos periódicos:\n",
    "        y_t ≈ β0 + Σ_k [a_k sin(2πk t / P) + b_k cos(2πk t / P)] + ...\n",
    "      donde P es el período (24 o 168) y k=1..K son los armónicos elegidos.\n",
    "    - Incluye **lags autoregresivos** (ARX) como y_{t-1}, y_{t-24}, y_{t-168} para capturar inercia\n",
    "      de corto/medio plazo, y **rollings** (promedios móviles) como componente de tendencia suave.\n",
    "    - Añade **exógenas**: temperatura y festivos.\n",
    "    - Se usa **Ridge** (L2) para estabilizar al tener muchas features (evita sobreajuste).\n",
    "\n",
    "(B) **Corrección de residuos con ML (Boosting)**\n",
    "    - Los residuos del modelo (A) pueden contener **no linealidades**/interacciones no capturadas.\n",
    "    - Un **HistGradientBoostingRegressor** aprende a predecir dichos residuos usando exógenas\n",
    "      y calendario (si se añade), y la predicción final es:\n",
    "        ŷ_t(final) = ŷ_t(A) + ŷ_t_residuos(ML)\n",
    "\n",
    "VALIDACIÓN WALK-FORWARD\n",
    "-----------------------\n",
    "- Se evalúa en los **últimos 90 días** con un **pronóstico recursivo**: cada hora predicha alimenta\n",
    "  los lags de las horas futuras (como en operación real). Métricas: **MAPE** y **RMSE**.\n",
    "\n",
    "TEMPERATURA FUTURA EN PRODUCCIÓN\n",
    "--------------------------------\n",
    "- Aquí se simula temperatura futura a partir de promedios (doy, hour) del último año.\n",
    "- En tu caso real: sustituir por un **pronóstico meteorológico** (Meteostat/NOAA/OpenWeatherMap).\n",
    "\n",
    "CÓMO ADAPTAR A TUS DATOS\n",
    "------------------------\n",
    "1) Reemplaza la función `build_panel()` por tu dataframe real (timestamp, subarea, demand, temp, holiday).\n",
    "2) Mantén `fourier_terms`, lags, rollings.\n",
    "3) Entrena y evalúa con `fit_models_for_subarea`, `walkforward_test`, y luego `recursive_forecast`.\n",
    "4) Ajusta hiperparámetros (K_DAILY/K_WEEKLY, lags, alpha de Ridge, profundidad del Boosting).\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0) PARÁMETROS GENERALES\n",
    "# =========================\n",
    "RANDOM_SEED   = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "N_SUBAREAS    = 6\n",
    "START_DATE    = \"2020-01-01 00:00:00\"\n",
    "END_DATE      = \"2024-12-31 23:00:00\"   # ~5 años de historia\n",
    "TEST_DAYS     = 90                      # ventana de evaluación (walk-forward)\n",
    "FORECAST_DAYS = 90                      # horizonte futuro ≈ 3 meses\n",
    "\n",
    "# Estacionalidades\n",
    "DAILY_PERIOD  = 24                      # ciclo diario\n",
    "WEEKLY_PERIOD = 24 * 7                  # ciclo semanal\n",
    "K_DAILY       = 3                       # nº de armónicos diarios\n",
    "K_WEEKLY      = 2                       # nº de armónicos semanales\n",
    "\n",
    "# Lags ARX\n",
    "LAGS = [1, 24, 168]                     # 1h, 1 día, 1 semana\n",
    "\n",
    "# =========================\n",
    "# 1) SIMULACIÓN DE DATOS\n",
    "# =========================\n",
    "def simulate_temperature(idx, subarea_id):\n",
    "    \"\"\"\n",
    "    Base teórica:\n",
    "    -------------\n",
    "    La temperatura se modela con un componente **anual** (seno), un **diario** (seno suave),\n",
    "    un pequeño sesgo por subárea y ruido blanco. Esto produce estacionalidad climática realista.\n",
    "    \"\"\"\n",
    "    dayofyear = idx.dayofyear.values\n",
    "    hour      = idx.hour.values\n",
    "\n",
    "    annual = 10 * np.sin(2 * pi * dayofyear / 365.25 - 0.8)      # amplitud ±10°C\n",
    "    daily  =  2 * np.sin(2 * pi * hour / 24.0 - 0.5)             # ciclo diario suave\n",
    "    bias   = (subarea_id - 3) * 0.3                              # sesgo por subárea\n",
    "    noise  = np.random.normal(0, 1.5, size=len(idx))\n",
    "\n",
    "    return 18 + annual + daily + bias + noise                     # base 18°C\n",
    "\n",
    "def simulate_demand(idx, subarea_id, temp):\n",
    "    \"\"\"\n",
    "    Base teórica:\n",
    "    -------------\n",
    "    La demanda agrega:\n",
    "    - Base por subárea\n",
    "    - Estacionalidad diaria (picos en mañana/noche) y semanal (fin de semana reduce)\n",
    "    - Estacionalidad anual suave\n",
    "    - Efecto temperatura (HDD/CDD respecto a 18°C)\n",
    "    - Festivos (reducción)\n",
    "    - Ruido blanco\n",
    "\n",
    "    Con esto, la relación demanda-temperatura no es lineal pura (heating/cooling degree).\n",
    "    \"\"\"\n",
    "    hour = idx.hour.values\n",
    "    dow  = idx.dayofweek.values\n",
    "    doy  = idx.dayofyear.values\n",
    "\n",
    "    base   = 220 + 20 * (subarea_id - 3) + np.random.normal(0, 5)  # nivel por subárea\n",
    "    daily  = 20 * np.sin(2 * pi * (hour - 8)  / 24.0) + 15 * np.sin(2 * pi * (hour - 19) / 24.0)\n",
    "    weekly = -25 * (dow >= 5).astype(float)                         # fin de semana menor\n",
    "    annual = 10 * np.cos(2 * pi * doy / 365.25)\n",
    "\n",
    "    # Festivos fijos por año (ejemplo)\n",
    "    holidays = pd.Series(0, index=idx)\n",
    "    for y in np.unique(idx.year):\n",
    "        for m, d in [(1,1), (5,1), (12,25)]:\n",
    "            try:\n",
    "                holidays[pd.Timestamp(y, m, d)] = 1\n",
    "            except:\n",
    "                pass\n",
    "    holidays = holidays.reindex(idx, fill_value=0).values\n",
    "    holiday_effect = -30 * holidays\n",
    "\n",
    "    # Efecto temperatura no lineal (HDD/CDD) alrededor de 18°C\n",
    "    hdd = np.maximum(0, 18 - temp)     # heating degree days\n",
    "    cdd = np.maximum(0, temp - 18)     # cooling degree days\n",
    "    temp_effect = 1.2 * hdd + 1.6 * cdd\n",
    "\n",
    "    noise = np.random.normal(0, 5, size=len(idx))\n",
    "    demand = base + daily + weekly + annual + temp_effect + holiday_effect + noise\n",
    "    return np.maximum(demand, 30), holidays   # piso mínimo\n",
    "\n",
    "def build_panel():\n",
    "    \"\"\"\n",
    "    Genera un panel (long) con:\n",
    "      timestamp | subarea | temp | demand | holiday\n",
    "    para las 6 subáreas y 5 años horarios.\n",
    "    \"\"\"\n",
    "    idx = pd.date_range(START_DATE, END_DATE, freq=\"H\")\n",
    "    dfs = []\n",
    "    for s in range(1, N_SUBAREAS + 1):\n",
    "        temp = simulate_temperature(idx, s)\n",
    "        demand, holidays = simulate_demand(idx, s, temp)\n",
    "        df = pd.DataFrame({\n",
    "            \"timestamp\": idx,\n",
    "            \"subarea\": f\"S{s}\",\n",
    "            \"temp\": temp,\n",
    "            \"demand\": demand,\n",
    "            \"holiday\": holidays\n",
    "        })\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Construcción del dataset simulado\n",
    "data = build_panel().sort_values([\"subarea\", \"timestamp\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 2) FEATURE ENGINEERING (FOURIER + LAGS + ROLL)\n",
    "# ============================================\n",
    "def fourier_terms(timestamps, period, K):\n",
    "    \"\"\"\n",
    "    Base teórica:\n",
    "    -------------\n",
    "    Los términos de Fourier (sin/cos) aproximan **estacionalidades periódicas** sin crear\n",
    "    24 ó 168 dummies. Con K armónicos, capturamos distintas frecuencias dentro del período.\n",
    "    \"\"\"\n",
    "    t = np.arange(len(timestamps))\n",
    "    out = {}\n",
    "    for k in range(1, K + 1):\n",
    "        out[f\"sin_{period}_{k}\"] = np.sin(2 * pi * k * t / period)\n",
    "        out[f\"cos_{period}_{k}\"] = np.cos(2 * pi * k * t / period)\n",
    "    return pd.DataFrame(out, index=timestamps)\n",
    "\n",
    "def add_lags(group_df, target_col=\"demand\", lags=LAGS):\n",
    "    \"\"\"\n",
    "    Base teórica:\n",
    "    -------------\n",
    "    Los lags ARX incorporan **memoria** del sistema: la demanda depende de su propio pasado\n",
    "    (y_{t-1}, y_{t-24}, y_{t-168}). Se añaden también **promedios móviles** como tendencia suave.\n",
    "    \"\"\"\n",
    "    for L in lags:\n",
    "        group_df[f\"lag_{L}\"] = group_df[target_col].shift(L)\n",
    "    group_df[\"roll24\"]  = group_df[target_col].rolling(24,  min_periods=1).mean()\n",
    "    group_df[\"roll168\"] = group_df[target_col].rolling(168, min_periods=1).mean()\n",
    "    return group_df\n",
    "\n",
    "# Aplicar lags por subárea (evita mezclar información entre grupos)\n",
    "data = data.groupby(\"subarea\", group_keys=False).apply(add_lags)\n",
    "\n",
    "# Fourier diarios y semanales sobre la malla temporal completa\n",
    "unique_ts = data[\"timestamp\"].drop_duplicates()\n",
    "ft_daily  = fourier_terms(unique_ts, DAILY_PERIOD,  K_DAILY)\n",
    "ft_weekly = fourier_terms(unique_ts, WEEKLY_PERIOD, K_WEEKLY)\n",
    "ft_all    = pd.concat([ft_daily, ft_weekly], axis=1).reset_index().rename(columns={\"index\": \"timestamp\"})\n",
    "\n",
    "# Incorporar Fourier al panel\n",
    "data = data.merge(ft_all, on=\"timestamp\", how=\"left\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) SPLIT TEMPORAL\n",
    "# =========================\n",
    "last_ts   = data[\"timestamp\"].max()\n",
    "test_start = last_ts - pd.Timedelta(days=TEST_DAYS) + pd.Timedelta(hours=1)\n",
    "\n",
    "# =========================\n",
    "# 4) MATRICES X / y\n",
    "# =========================\n",
    "ridge_features = (\n",
    "    [\"temp\", \"holiday\", \"roll24\", \"roll168\"] +\n",
    "    [c for c in data.columns if c.startswith(\"sin_\") or c.startswith(\"cos_\")] +\n",
    "    [f\"lag_{L}\" for L in LAGS]\n",
    ")\n",
    "\n",
    "def prepare_xy(df):\n",
    "    \"\"\"\n",
    "    Construye X (features) e y (objetivo) y descarta filas con NaN (por lags iniciales).\n",
    "    \"\"\"\n",
    "    X = df[ridge_features].copy()\n",
    "    y = df[\"demand\"].copy()\n",
    "    valid = ~X.isna().any(axis=1) & y.notna()\n",
    "    return X[valid], y[valid], valid\n",
    "\n",
    "# ==========================================\n",
    "# 5) ENTRENAMIENTO Y PRONÓSTICO POR SUBÁREA\n",
    "# ==========================================\n",
    "def fit_models_for_subarea(df_sub):\n",
    "    \"\"\"\n",
    "    Ajusta:\n",
    "      (A) RidgeCV sobre Fourier + ARX + exógenas\n",
    "      (B) Boosting (HGBR) sobre RESIDUOS del (A), con features exógenas (temp, holiday).\n",
    "    \"\"\"\n",
    "    train_mask = df_sub[\"timestamp\"] < test_start\n",
    "    test_mask  = df_sub[\"timestamp\"] >= test_start\n",
    "\n",
    "    X_train, y_train, vtrain = prepare_xy(df_sub[train_mask])\n",
    "\n",
    "    # --- Capa A: Ridge con búsqueda de alpha por CV logaritmica\n",
    "    ridge = RidgeCV(alphas=np.logspace(-3, 3, 13), fit_intercept=True)\n",
    "    ridge.fit(X_train, y_train)\n",
    "\n",
    "    # Residuos en train (para entrenar ML de residuos)\n",
    "    resid_train = y_train - ridge.predict(X_train)\n",
    "\n",
    "    # --- Capa B: ML para residuos (rápido y robusto)\n",
    "    ml_features = [\"temp\", \"holiday\"]    # en producción puedes añadir dummies de hora/día si lo deseas\n",
    "    X_train_ml  = df_sub[train_mask].loc[vtrain, ml_features]\n",
    "    ml = HistGradientBoostingRegressor(random_state=RANDOM_SEED, max_depth=6)\n",
    "    ml.fit(X_train_ml, resid_train)\n",
    "\n",
    "    return ridge, ml, {\"ml_features\": ml_features}\n",
    "\n",
    "def recursive_forecast(df_sub, ridge, ml, horizon_hours, start_time):\n",
    "    \"\"\"\n",
    "    Pronóstico recursivo a partir de 'start_time' por 'horizon_hours' horas.\n",
    "\n",
    "    Base teórica:\n",
    "    -------------\n",
    "    - En operación, no tenemos el futuro real de y; por eso **retroalimentamos** el pronóstico\n",
    "      (yhat) a los lags para la siguiente hora. Esta recursividad evita usar \"futuros reales\".\n",
    "    - Las features determinísticas (Fourier) y exógenas conocidas (p. ej. festivos programados,\n",
    "      pronóstico de temperatura) sí están disponibles.\n",
    "    \"\"\"\n",
    "    # Historial hasta start_time (incluye valores reales para lags iniciales)\n",
    "    hist = df_sub[df_sub[\"timestamp\"] <= start_time].copy().reset_index(drop=True)\n",
    "    # Índice futuro\n",
    "    future_index = pd.date_range(start_time + pd.Timedelta(hours=1), periods=horizon_hours, freq=\"H\")\n",
    "    future = pd.DataFrame({\"timestamp\": future_index, \"subarea\": hist[\"subarea\"].iloc[0]})\n",
    "\n",
    "    # --- Temperatura futura aproximada:\n",
    "    #     promediamos por (día del año, hora) del último año histórico para esa subárea.\n",
    "    last_year_mask = hist[\"timestamp\"] >= (hist[\"timestamp\"].max() - pd.Timedelta(days=365))\n",
    "    last_year = hist.loc[last_year_mask].copy()\n",
    "    last_year[\"hour\"] = last_year[\"timestamp\"].dt.hour\n",
    "    last_year[\"doy\"]  = last_year[\"timestamp\"].dt.dayofyear\n",
    "    grid = last_year.groupby([\"doy\", \"hour\"])[\"temp\"].mean().reset_index()\n",
    "\n",
    "    future[\"hour\"] = future[\"timestamp\"].dt.hour\n",
    "    future[\"doy\"]  = future[\"timestamp\"].dt.dayofyear\n",
    "    future = future.merge(grid, on=[\"doy\", \"hour\"], how=\"left\", suffixes=(\"\", \"_mean\"))\n",
    "    future[\"temp\"] = future[\"temp\"].fillna(last_year[\"temp\"].mean())\n",
    "\n",
    "    # --- Festivos futuros (mismo patrón simple)\n",
    "    future[\"holiday\"] = 0\n",
    "    for y in np.unique(future[\"timestamp\"].dt.year):\n",
    "        for m, d in [(1,1), (5,1), (12,25)]:\n",
    "            t = pd.Timestamp(y, m, d)\n",
    "            if t in set(future[\"timestamp\"]):\n",
    "                future.loc[future[\"timestamp\"] == t, \"holiday\"] = 1\n",
    "\n",
    "    # --- Fourier para hist+futuro (mantiene fase coherente)\n",
    "    full_idx = pd.DatetimeIndex(pd.concat([hist[\"timestamp\"], future[\"timestamp\"]]))\n",
    "    ft_d = fourier_terms(full_idx, DAILY_PERIOD,  K_DAILY)\n",
    "    ft_w = fourier_terms(full_idx, WEEKLY_PERIOD, K_WEEKLY)\n",
    "    ft_full = pd.concat([ft_d, ft_w], axis=1).reset_index().rename(columns={\"index\": \"timestamp\"})\n",
    "    hist   = hist.merge(ft_full, on=\"timestamp\", how=\"left\")\n",
    "    future = future.merge(ft_full, on=\"timestamp\", how=\"left\")\n",
    "\n",
    "    # Serie yhat (usamos reales hasta start_time)\n",
    "    hist[\"yhat\"] = hist[\"demand\"]\n",
    "\n",
    "    def update_lags_and_rolls(df):\n",
    "        for L in LAGS:\n",
    "            df[f\"lag_{L}\"] = df[\"yhat\"].shift(L)\n",
    "        df[\"roll24\"]  = df[\"yhat\"].rolling(24,  min_periods=1).mean()\n",
    "        df[\"roll168\"] = df[\"yhat\"].rolling(168, min_periods=1).mean()\n",
    "        return df\n",
    "\n",
    "    hist = update_lags_and_rolls(hist)\n",
    "\n",
    "    preds      = []\n",
    "    ridge_cols = [c for c in ridge_features if (c in hist.columns) or (c in future.columns)]\n",
    "    ml_cols    = [\"temp\", \"holiday\"]\n",
    "\n",
    "    for t in future[\"timestamp\"]:\n",
    "        row_fut = future[future[\"timestamp\"] == t].copy()\n",
    "        tmp     = pd.concat([hist, row_fut], ignore_index=True, sort=False)\n",
    "        tmp     = update_lags_and_rolls(tmp)\n",
    "\n",
    "        # Capa A (Ridge)\n",
    "        Xr = tmp.iloc[[-1]][ridge_cols].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "        yhat_A = ridge.predict(Xr)[0]\n",
    "\n",
    "        # Capa B (Residuos)\n",
    "        Xm = tmp.iloc[[-1]][ml_cols].fillna(0)\n",
    "        yhat_res = ml.predict(Xm)[0]\n",
    "\n",
    "        yhat = yhat_A + yhat_res\n",
    "\n",
    "        # Registrar y realimentar para siguientes lags\n",
    "        new_row = tmp.iloc[[-1]].copy()\n",
    "        new_row[\"yhat\"]   = yhat\n",
    "        new_row[\"demand\"] = np.nan\n",
    "        hist = pd.concat([hist, new_row], ignore_index=True, sort=False)\n",
    "\n",
    "        preds.append({\"timestamp\": t, \"subarea\": hist[\"subarea\"].iloc[0], \"yhat\": yhat})\n",
    "\n",
    "    return pd.DataFrame(preds)\n",
    "\n",
    "def walkforward_test(df_sub, ridge, ml):\n",
    "    \"\"\"\n",
    "    Evalúa en los últimos TEST_DAYS días con pronóstico recursivo (walk-forward).\n",
    "    Devuelve arrays (y_true, y_pred) para calcular métricas.\n",
    "    \"\"\"\n",
    "    t0 = df_sub.loc[df_sub[\"timestamp\"] >= test_start, \"timestamp\"].min()\n",
    "    t1 = df_sub[\"timestamp\"].max()\n",
    "    horizon_hours = int((t1 - t0) / pd.Timedelta(hours=1)) + 1\n",
    "\n",
    "    preds = recursive_forecast(df_sub, ridge, ml, horizon_hours, start_time=t0 - pd.Timedelta(hours=1))\n",
    "    truth = df_sub[(df_sub[\"timestamp\"] >= t0) & (df_sub[\"timestamp\"] <= t1)][[\"timestamp\", \"demand\"]].reset_index(drop=True)\n",
    "    out = preds.merge(truth, on=\"timestamp\", how=\"left\")\n",
    "    return out[\"demand\"].values, out[\"yhat\"].values\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# 6) ENTRENAR, EVALUAR Y PRONOSTICAR\n",
    "# ======================================\n",
    "metrics_rows   = []\n",
    "future_forests = []\n",
    "\n",
    "for sub in data[\"subarea\"].unique():\n",
    "    df_sub = data[data[\"subarea\"] == sub].copy().reset_index(drop=True)\n",
    "\n",
    "    # Entrenamiento por subárea\n",
    "    ridge, ml, meta = fit_models_for_subarea(df_sub)\n",
    "\n",
    "    # Evaluación walk-forward en TEST\n",
    "    y_true, y_pred = walkforward_test(df_sub, ridge, ml)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    metrics_rows.append({\"subarea\": sub, \"MAPE_%\": mape, \"RMSE\": rmse})\n",
    "\n",
    "    # Pronóstico futuro 90 días\n",
    "    start_time = df_sub[\"timestamp\"].max()\n",
    "    horizon_hours = FORECAST_DAYS * 24\n",
    "    fut = recursive_forecast(df_sub, ridge, ml, horizon_hours, start_time)\n",
    "    future_forests.append(fut)\n",
    "\n",
    "# Métricas por subárea y global\n",
    "metrics_df = pd.DataFrame(metrics_rows)\n",
    "metrics_df.loc[len(metrics_df)] = {\"subarea\": \"GLOBAL\",\n",
    "                                   \"MAPE_%\": metrics_df[\"MAPE_%\"].mean(),\n",
    "                                   \"RMSE\":   metrics_df[\"RMSE\"].mean()}\n",
    "\n",
    "# Consolidar pronóstico futuro\n",
    "forecast_df = pd.concat(future_forests, ignore_index=True).rename(columns={\"yhat\": \"forecast\"})\n",
    "\n",
    "# =========================\n",
    "# 7) SALIDAS\n",
    "# =========================\n",
    "print(\"\\nMÉTRICAS WALK-FORWARD (últimos 90 días):\")\n",
    "print(metrics_df)\n",
    "\n",
    "print(\"\\nHEAD del pronóstico futuro (primeras 10 filas):\")\n",
    "print(forecast_df.head(10))\n",
    "\n",
    "# (Opcional) Guardar CSV\n",
    "# forecast_df.to_csv(\"forecast_3m_simulado_por_subarea.csv\", index=False)\n",
    "\n",
    "# (Opcional) Gráficas rápidas para una subárea\n",
    "# sub_demo = \"S1\"\n",
    "# df_sub = data[data[\"subarea\"] == sub_demo].copy().reset_index(drop=True)\n",
    "# ridge, ml, _ = fit_models_for_subarea(df_sub)\n",
    "# y_true_test, y_pred_test = walkforward_test(df_sub, ridge, ml)\n",
    "# t0 = df_sub.loc[df_sub[\"timestamp\"] >= test_start, \"timestamp\"].min()\n",
    "# t1 = df_sub[\"timestamp\"].max()\n",
    "# test_index = pd.date_range(t0, t1, freq=\"H\")\n",
    "# plot_df = pd.DataFrame({\"timestamp\": test_index, \"y_true\": y_true_test, \"y_pred\": y_pred_test})\n",
    "# last_14 = plot_df[\"timestamp\"] >= (plot_df[\"timestamp\"].max() - pd.Timedelta(days=14))\n",
    "# plt.figure(figsize=(12,4))\n",
    "# plt.plot(plot_df[last_14][\"timestamp\"], plot_df[last_14][\"y_true\"], label=\"Real\")\n",
    "# plt.plot(plot_df[last_14][\"timestamp\"], plot_df[last_14][\"y_pred\"], label=\"Pred\")\n",
    "# plt.title(f\"Subárea {sub_demo} – Test (últimos 14 días)\")\n",
    "# plt.xlabel(\"Fecha\"); plt.ylabel(\"Demanda\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
