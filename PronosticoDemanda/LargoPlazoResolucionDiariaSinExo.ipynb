{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "PRONÓSTICO DIARIO A 1 AÑO POR SUBÁREA (SIN TEMPERATURA)\n",
    "=======================================================\n",
    "\n",
    "Objetivo\n",
    "--------\n",
    "Pronosticar la demanda eléctrica **diaria** (no horaria) por subárea, a **365 días**.\n",
    "Se usan 5 años diarios simulados, y un enfoque robusto para largo plazo:\n",
    "\n",
    "- Modelo base: **SARIMAX** con estacionalidad semanal (periodo 7) vía (0,1,1)(0,1,1,7),\n",
    "  y **estacionalidad anual** capturada con **términos de Fourier** (periodo ~365.25).\n",
    "- Exógenas de calendario: **día-de-semana (dummies)** y **festivos**.\n",
    "- Evaluación: **hold-out del último año**: se entrena con años previos y se pronostica\n",
    "  365 días para comparar vs observaciones reales del último año.\n",
    "- Baseline: **naïve anual** (valor de hace 365 días).\n",
    "- Pronóstico final: 365 días futuros (después del último punto observado) con las exógenas futuras.\n",
    "\n",
    "Base teórica (resumen)\n",
    "----------------------\n",
    "1) **SARIMA/SARIMAX**:\n",
    "   - Parte ARIMA: diferenciar para estacionariedad en media/tendencia.\n",
    "   - Parte SARIMA: diferencia estacional de periodo 7 para patrón semanal.\n",
    "   - **Orden elegido**: (0,1,1)(0,1,1,7) es un \"caballo de batalla\" habitual que\n",
    "     funciona bien para consumo diario con semana laboral vs fin de semana.\n",
    "\n",
    "2) **Fourier anual como exógena**:\n",
    "   - Para estacionalidad larga (≈ 365 días), usar términos sin/cos\n",
    "     sin crear 365 dummies: con K armónicos capturamos variaciones suaves anuales.\n",
    "     ŷ_t ≈ β0 + Σ_{k=1..K} [a_k sin(2π k t / 365.25) + b_k cos(2π k t / 365.25)] + ...\n",
    "   - Aquí usamos K=3 (puedes subir a 5 si la forma anual es compleja).\n",
    "\n",
    "3) **Exógenas de calendario**:\n",
    "   - Dummies de día-de-semana y **festivo** (0/1) ayudan a la forma semanal y eventos fijos.\n",
    "\n",
    "4) **Validación para largo plazo**:\n",
    "   - Evitar recursión hora-a-hora. Aquí el horizonte es diario y el modelo pronostica\n",
    "     directamente 365 pasos usando su estructura probabilística + exógenas futuras.\n",
    "\n",
    "Cómo adaptar a datos reales\n",
    "---------------------------\n",
    "- Reemplaza la simulación por tu DataFrame con columnas:\n",
    "  `date` (diaria), `subarea` (string), `demand` (float), `holiday` (0/1).\n",
    "- Si tu histórico es horario, **agrega**: demanda diaria = suma/avg por día y subárea.\n",
    "- Mantén el pipeline de Fourier (anual), dummies (dow) y festivos.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "from itertools import product\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0) PARÁMETROS GENERALES\n",
    "# =========================\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "N_SUBAREAS  = 6\n",
    "START_DATE  = \"2020-01-01\"\n",
    "END_DATE    = \"2024-12-31\"    # ~5 años diarios\n",
    "TEST_DAYS   = 365             # último año para evaluación\n",
    "FORECAST_H  = 365             # horizonte futuro (1 año)\n",
    "\n",
    "FOURIER_PERIOD = 365.25\n",
    "K_FOURIER      = 3            # armónicos anuales (sube a 5 si necesitas más detalle)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) SIMULACIÓN DIARIA\n",
    "# =========================\n",
    "def simulate_daily_demand(idx, subarea_id):\n",
    "    \"\"\"\n",
    "    Simula demanda DIARIA sin temperatura:\n",
    "    - Nivel por subárea\n",
    "    - Efecto semanal (dow): menor en sáb-dom\n",
    "    - Estacionalidad anual suave (Fourier) + leve tendencia\n",
    "    - Festivos (reducción)\n",
    "    - Ruido\n",
    "    \"\"\"\n",
    "    dow = idx.dayofweek.values    # 0..6\n",
    "    doy = idx.dayofyear.values\n",
    "\n",
    "    # Nivel base distinto por subárea\n",
    "    base = 220 + 18*(subarea_id - 3)\n",
    "\n",
    "    # Semana: bajón en fin de semana\n",
    "    weekly = -18 * (dow >= 5).astype(float)\n",
    "\n",
    "    # Estacionalidad anual suave con 2 armónicos \"duros\" + ruido\n",
    "    annual = 10*np.sin(2*pi*doy/365.25) + 6*np.cos(2*pi*2*doy/365.25)\n",
    "\n",
    "    # Tendencia ligera\n",
    "    t = np.arange(len(idx))\n",
    "    trend = 0.003 * t\n",
    "\n",
    "    # Festivos (mismo set fijo a modo de ejemplo)\n",
    "    holidays = pd.Series(0, index=idx)\n",
    "    for y in np.unique(idx.year):\n",
    "        for m, d in [(1,1), (5,1), (12,25)]:\n",
    "            try:\n",
    "                holidays[pd.Timestamp(y, m, d)] = 1\n",
    "            except:\n",
    "                pass\n",
    "    holidays = holidays.reindex(idx, fill_value=0).astype(int).values\n",
    "    holiday_effect = -25 * holidays\n",
    "\n",
    "    # Ruido\n",
    "    noise = np.random.normal(0, 5, size=len(idx))\n",
    "\n",
    "    y = base + weekly + annual + trend + holiday_effect + noise\n",
    "    return np.maximum(y, 10), holidays\n",
    "\n",
    "\n",
    "def build_daily_panel():\n",
    "    \"\"\"\n",
    "    DataFrame largo:\n",
    "      date | subarea | demand | holiday\n",
    "    \"\"\"\n",
    "    idx = pd.date_range(START_DATE, END_DATE, freq=\"D\")\n",
    "    dfs = []\n",
    "    for s in range(1, N_SUBAREAS+1):\n",
    "        demand, holidays = simulate_daily_demand(idx, s)\n",
    "        df = pd.DataFrame({\n",
    "            \"date\": idx,\n",
    "            \"subarea\": f\"S{s}\",\n",
    "            \"demand\": demand,\n",
    "            \"holiday\": holidays\n",
    "        })\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "data = build_daily_panel().sort_values([\"subarea\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) EXÓGENAS (FOURIER + CALENDARIO)\n",
    "# =========================\n",
    "def fourier_terms(dates, period=FOURIER_PERIOD, K=K_FOURIER, prefix=\"year\"):\n",
    "    \"\"\"\n",
    "    Términos de Fourier (sin/cos) para estacionalidad periódica (aquí anual).\n",
    "    No explotan dimensionalidad como 365 dummies y suelen generalizar mejor.\n",
    "    \"\"\"\n",
    "    t = np.arange(len(dates))\n",
    "    out = {}\n",
    "    for k in range(1, K+1):\n",
    "        out[f\"{prefix}_sin_{k}\"] = np.sin(2*pi*k*t/period)\n",
    "        out[f\"{prefix}_cos_{k}\"] = np.cos(2*pi*k*t/period)\n",
    "    return pd.DataFrame(out, index=dates)\n",
    "\n",
    "def build_exog(df):\n",
    "    \"\"\"\n",
    "    Exógenas de calendario + Fourier:\n",
    "    - Dummies de día-de-semana (dow_1..dow_6, con base dow_0)\n",
    "    - Festivo (0/1)\n",
    "    - Fourier anual (K armónicos)\n",
    "    \"\"\"\n",
    "    exog = pd.DataFrame(index=df.index)\n",
    "    # Día de semana (0..6). drop_first=True para evitar colinealidad.\n",
    "    dow = pd.get_dummies(df[\"date\"].dt.dayofweek, prefix=\"dow\", drop_first=True).astype(int)\n",
    "    exog = pd.concat([exog, dow], axis=1)\n",
    "\n",
    "    # Festivo (ya viene en df)\n",
    "    exog[\"holiday\"] = df[\"holiday\"].astype(int).values\n",
    "\n",
    "    # Fourier anual\n",
    "    ft = fourier_terms(df[\"date\"], period=FOURIER_PERIOD, K=K_FOURIER, prefix=\"yr\")\n",
    "    ft.index = df.index\n",
    "    exog = pd.concat([exog, ft], axis=1)\n",
    "\n",
    "    return exog\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) SPLIT: TRAIN / TEST\n",
    "# =========================\n",
    "last_day   = data[\"date\"].max()\n",
    "test_start = last_day - pd.Timedelta(days=TEST_DAYS) + pd.Timedelta(days=1)  # inicio del año hold-out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) ENTRENAMIENTO Y TEST\n",
    "# =========================\n",
    "def fit_sarimax_daily(y, exog, order=(0,1,1), seasonal_order=(0,1,1,7)):\n",
    "    \"\"\"\n",
    "    Ajusta un SARIMAX(y ~ exog) con:\n",
    "    - Diferencia no estacional (d=1) para tendencia\n",
    "    - Diferencia estacional semanal (D=1, s=7) para componente semanal\n",
    "    - Componentes MA (no estacional y estacional) para captar autocorrelaciones residuales\n",
    "    Esta especificación es robusta y suele rendir bien con consumo/energía diarios.\n",
    "    \"\"\"\n",
    "    model = SARIMAX(\n",
    "        endog=y,\n",
    "        exog=exog,\n",
    "        order=order,\n",
    "        seasonal_order=seasonal_order,\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False\n",
    "    )\n",
    "    res = model.fit(disp=False)\n",
    "    return res\n",
    "\n",
    "\n",
    "def prep_exog_consistent(train_df, test_df, future_df):\n",
    "    \"\"\"\n",
    "    Asegura que TRAIN/TEST/FUTURE tengan **exactamente** las mismas columnas exógenas\n",
    "    (p. ej., si en un segmento falta una categoría de dow).\n",
    "    \"\"\"\n",
    "    ex_tr = build_exog(train_df).copy()\n",
    "    ex_te = build_exog(test_df).copy()\n",
    "    ex_fu = build_exog(future_df).copy()\n",
    "\n",
    "    cols = sorted(set(ex_tr.columns) | set(ex_te.columns) | set(ex_fu.columns))\n",
    "    ex_tr = ex_tr.reindex(columns=cols, fill_value=0)\n",
    "    ex_te = ex_te.reindex(columns=cols, fill_value=0)\n",
    "    ex_fu = ex_fu.reindex(columns=cols, fill_value=0)\n",
    "    return ex_tr, ex_te, ex_fu\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5) LOOP POR SUBÁREA\n",
    "# =========================\n",
    "results = []\n",
    "forecasts = []\n",
    "\n",
    "for sub in data[\"subarea\"].unique():\n",
    "    df_sub = data[data[\"subarea\"] == sub].copy().reset_index(drop=True)\n",
    "\n",
    "    # Particiones\n",
    "    df_train = df_sub[df_sub[\"date\"] < test_start].copy()\n",
    "    df_test  = df_sub[df_sub[\"date\"] >= test_start].copy()  # último año (para evaluar)\n",
    "\n",
    "    # Exógenas consistentes\n",
    "    ex_tr, ex_te, ex_fu_dummy = prep_exog_consistent(df_train, df_test, df_test)  # futuro real lo armamos luego\n",
    "\n",
    "    # Ajustar SARIMAX en TRAIN\n",
    "    y_tr = df_train[\"demand\"].values\n",
    "    model_res = fit_sarimax_daily(y_tr, ex_tr)\n",
    "\n",
    "    # PRONÓSTICO DEL AÑO HOLD-OUT (TEST) para evaluar\n",
    "    yhat_test = model_res.predict(start=len(y_tr), end=len(y_tr)+len(df_test)-1, exog=ex_te)\n",
    "    y_true    = df_test[\"demand\"].values\n",
    "\n",
    "    mape = mean_absolute_percentage_error(y_true, yhat_test) * 100\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, yhat_test))\n",
    "\n",
    "    # Baseline naïve anual (mismo día del año pasado)\n",
    "    # Tomamos el valor de hace 365 días en TRAIN si existe; alineamos tamaños\n",
    "    if len(df_train) >= 365:\n",
    "        naive_last_year = df_train[\"demand\"].values[-365:][:len(df_test)]\n",
    "        mape_naive = mean_absolute_percentage_error(y_true, naive_last_year) * 100\n",
    "    else:\n",
    "        mape_naive = np.nan\n",
    "\n",
    "    results.append({\"subarea\": sub, \"MAPE_%\": mape, \"RMSE\": rmse, \"MAPE_naive_%\": mape_naive})\n",
    "\n",
    "    # =========================\n",
    "    # 6) PRONÓSTICO FUTURO 365 DÍAS\n",
    "    # =========================\n",
    "    last_obs = df_sub[\"date\"].max()\n",
    "    future_idx = pd.date_range(last_obs + pd.Timedelta(days=1), periods=FORECAST_H, freq=\"D\")\n",
    "    df_future = pd.DataFrame({\n",
    "        \"date\": future_idx,\n",
    "        \"subarea\": sub,\n",
    "        # festivos futuros simples (reemplaza por tu calendario real)\n",
    "        \"holiday\": 0\n",
    "    })\n",
    "    for y in np.unique(df_future[\"date\"].dt.year):\n",
    "        for m, d in [(1,1), (5,1), (12,25)]:\n",
    "            ts = pd.Timestamp(y, m, d)\n",
    "            if ts in set(df_future[\"date\"]):\n",
    "                df_future.loc[df_future[\"date\"] == ts, \"holiday\"] = 1\n",
    "\n",
    "    # Preparar exógenas para FUTURE (mismas columnas)\n",
    "    ex_tr2, ex_te2, ex_fu = prep_exog_consistent(df_train, df_test, df_future)\n",
    "\n",
    "    # Reentrenar con TODO el histórico antes del futuro (opcional pero recomendable)\n",
    "    ex_full = build_exog(df_sub).reindex(columns=ex_tr2.columns, fill_value=0)\n",
    "    model_res_full = fit_sarimax_daily(df_sub[\"demand\"].values, ex_full)\n",
    "\n",
    "    # Pronóstico 365 días FUTURO\n",
    "    yhat_future = model_res_full.predict(start=len(df_sub), end=len(df_sub)+FORECAST_H-1, exog=ex_fu)\n",
    "\n",
    "    forecasts.append(pd.DataFrame({\n",
    "        \"date\": future_idx,\n",
    "        \"subarea\": sub,\n",
    "        \"forecast\": yhat_future\n",
    "    }))\n",
    "\n",
    "# Métricas por subárea + global\n",
    "metrics_df = pd.DataFrame(results)\n",
    "metrics_df.loc[len(metrics_df)] = {\n",
    "    \"subarea\": \"GLOBAL\",\n",
    "    \"MAPE_%\": metrics_df[\"MAPE_%\"].mean(),\n",
    "    \"RMSE\": metrics_df[\"RMSE\"].mean(),\n",
    "    \"MAPE_naive_%\": metrics_df[\"MAPE_naive_%\"].mean()\n",
    "}\n",
    "\n",
    "print(\"\\nMÉTRICAS HOLD-OUT (último año):\")\n",
    "print(metrics_df.round(3))\n",
    "\n",
    "forecast_df = pd.concat(forecasts, ignore_index=True).sort_values([\"subarea\",\"date\"])\n",
    "print(\"\\nHEAD del pronóstico futuro (primeras 10 filas):\")\n",
    "print(forecast_df.head(10))\n",
    "\n",
    "# (Opcional) Guardar a CSV\n",
    "# forecast_df.to_csv(\"forecast_diario_1anio_por_subarea.csv\", index=False)\n",
    "\n",
    "# (Opcional) Gráfica rápida para una subárea\n",
    "# sub_demo = \"S1\"\n",
    "# df_sub = data[data[\"subarea\"] == sub_demo].copy().reset_index(drop=True)\n",
    "# df_train = df_sub[df_sub[\"date\"] < test_start]\n",
    "# df_test  = df_sub[df_sub[\"date\"] >= test_start]\n",
    "# ex_tr, ex_te, _ = prep_exog_consistent(df_train, df_test, df_test)\n",
    "# res = fit_sarimax_daily(df_train[\"demand\"].values, ex_tr)\n",
    "# yhat_test = res.predict(start=len(df_train), end=len(df_train)+len(df_test)-1, exog=ex_te)\n",
    "# plt.figure(figsize=(12,4))\n",
    "# plt.plot(df_test[\"date\"], df_test[\"demand\"], label=\"Real\")\n",
    "# plt.plot(df_test[\"date\"], yhat_test, label=\"Pronóstico\")\n",
    "# plt.title(f\"Subárea {sub_demo} – Último año (hold-out)\")\n",
    "# plt.xlabel(\"Fecha\"); plt.ylabel(\"Demanda diaria\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
